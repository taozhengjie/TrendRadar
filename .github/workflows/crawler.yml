name: Hot News Crawler

on:
  schedule:
    - cron: "0 9-21/2 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          ref: master     # ⭐ 强制同步远程最新 master

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run crawler
        env:
          GITHUB_ACTIONS: true
        run: python main.py

      - name: Update index.html
        run: |
          latest_html=$(find output -type f -name "*.html" | sort -r | head -n 1)
          cp "$latest_html" index.html

      - name: Update latest.html
        run: |
          latest_summary=$(find output -type f -name "当日汇总.html" | sort -r | head -n 1)
          cp "$latest_summary" latest.html

      - name: Commit all changes together
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add index.html latest.html
          git commit -m "Update pages" || echo "No changes"

      - name: Push once
        uses: ad-m/github-push-action@v0.8.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: master
